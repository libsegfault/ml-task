# Отчёт по практическому заданию на тему "Классификация комментариев на ревью"

## Классические методы машинного обучения (`RandomForestClassifier`)
Изначальные параметры (`min_samples_split=5`) уже дают достаточно хорошие результаты:
|  Метрика  |  Среднее значение  | Стандартное отклонение |
| --------- | ------------------ | ---------------------- |
| precision | 0.6155871485943775 |  0.035370559561768704  |
| recall    | 0.8857340800015117 |  0.017333983289874847  |
| f1        | 0.7258686225334474 |  0.027210884601059766  |

Матрица несоответствия:
|         |    +    |    -    |
| ------- | ------- | ------- |
|    +    |  1016.0 |    95.8 |
|    -    |    19.8 |   153.4 |

Можно немного улучшить результаты, подобрав другие параметры (`max_features='sqrt'`, `min_samples_split=3`,  `n_estimators=100`):
|  Метрика  |  Среднее значение  | Стандартное отклонение |
| --------- | ------------------ | ---------------------- |
| precision | 0.6212064257028113 |  0.037720125569664996  |
| recall    | 0.8873030406230094 |  0.01449640751542271   |
| f1        | 0.730151951327308  |  0.02695825831815383   |

Матрица несоответствия (среднее по всем запускам):
|         |    +    |    -    |
| ------- | ------- | ------- |
|    +    |  1016.1 |    94.4 |
|    -    |    19.7 |   154.8 |

В обоих случаях число ложноотрицательных результатов оказывается кратно больше ложноположительных, то есть модель скорее пропустит "плохой" комментарий, чем неверно укажет на "хороший".

## Предобученные модели (`transformers`)
В качестве предобученной модели было решено выбрать [Tiny-Toxic-Detector](https://huggingface.co/AssistantsLab/Tiny-Toxic-Detector), так как она значительно быстрее всех других: [лучшая](https://huggingface.co/JungleLee/bert-toxic-comment-classification) (с результатом `f1≈0.61`) из протестированных в 33(!) раза медленнее.

После дообучения на данном наборе данных модель показывает целевые результаты (`f1 > 0.7`):
|  Метрика  |      Значение      |
| --------- | ------------------ |
| precision | 0.6046511627906976 |
| recall    | 0.8614457831325302 |
| f1        | 0.7105590062111802 |

Матрица несоответствия:
|         |    +    |    -    |
| ------- | ------- | ------- |
|    +    |  2051.0 |    46.0 |
|    -    |   187.0 |   286.0 |

Число ложноположительных результатов больше, чем ложноотрицательных, что связано с тем, что данная модель была обучена на специально подобранном *очень точном* наборе данных, в котором нет явно некорректных данных (в отличие от того, который требуется использовать в данном задании).

## Вывод

Классические методы (на примере `RandomForestClassifier`) оказались лучше предобученных моделей по всем важным параметрам: метрики (незначительно), скорость работы. Для улучшения метрик у последних требуется значительно жертвовать скоростью работы и/или использовать специализорованные ускорители, неограниченный доступ к которым в рамках курса не предоставляется.

## Приложение (проблемы)
- Постоянные проблемы с типами, ошибки времени выполнения и необходимость искать примеры для каждой функции или метода (а их обычно нет или они не подходят из-за особенностей задания). Решения нет, проблема в динамической типизации Python
- Чрезвычайно медленная работа RoBERTa, CodeBERT и других моделей этого класса. Частичное решение - [Tiny-Toxic-Detector](https://huggingface.co/AssistantsLab/Tiny-Toxic-Detector), но обучение всё ещё занимает около 10 минут
- PEP 668. Решение: `echo 'export PIP_BREAK_SYSTEM_PACKAGES=1' >> ~/.bashrc` (venv - отстой) и установка пакетов из репозиториев, если они доступны.
- Сломанный код шаблона. Решение - 19d19b895f581aee76ced76075fd2bd168728f64
